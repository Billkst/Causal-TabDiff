
论文题目：基于因果表征学习的肺癌预防控制辅助决策研究与实现

# 一、学位论文研究内容

# 1. 研究目标

本研究依据美国国家癌症研究所（NCI）提出的癌症控制连续体框架（The Cancer Control Continuum）和《预防医学》第八版教材中关于疾病分级预防的理论体系，聚焦于肺癌预防控制的关键阶段，旨在利用因果表征学习与生成式人工智能等技术，构建覆盖一级预防（病因分析）与二级预防（筛检与随访管理）的智能辅助决策体系。具体目标如下：1）构建基于因果发现与超图学习的危险因素分析模型。利用因果解耦技术从多模态数据中剥离强混杂因素，构建超图神经网络量化环境暴露与遗传易感性之间的非线性协同病因机制（即环境“促癌”与基因“驱动”的高阶交互机制），从而揭示肺癌的病因机制，为制定精准的一级预防策略提供量化依据；2）提出基于因果扩散模型的高危人群识别方法。利用扩散模型的生成能力，解决回顾性医疗数据中存在的数据异构性（连续与离散混合）、时序稀疏性（随访不连续）以及幸存者偏差问题。通过捕捉肺癌与慢阻肺（COPD）等伴生疾病的共病模式，利用反事实推理重建个体在不同干预条件下的风险演变轨迹，从而精准锁定隐匿的高危个体；3）构建基于因果解耦与神经符号推理的随访建议生成智能体。设计潜在语义特征交互机制，解决电子病历中“重度吸烟”等定性描述与《指南》中“吸烟指数”等定量标准之间的匹配难题。构建知识驱动的临床推理智能体，实现针对肺癌高风险人群的随访建议生成，确保生成结果符合《中国肺癌筛查与早诊早治指南》规范；4）构建肺癌预防控制辅助决策平台。集成上述模型功能，辅助公共卫生人员与临床医生实现肺癌防控流程的闭环管理。

# 2.研究内容

本文的主要内容是关于肺癌预防控制过程中的危险因素分析、高危人群识别、随访建议生成以及肺癌预防控制辅助决策平台开发。

# （1）基于因果发现与超图学习的危险因素分析

现有的肺癌病因学研究多依赖传统的广义线性模型或纯数据驱动的深度学习方法。然而，传统线性模型在处理多模态流行病学数据时，通常假设各风险因素对效应的影响呈可加性，难以拟合生物学上客观存在的“环境-基因”非线性协同病因机制（即环境因子作为促癌剂促进基因突变致癌）；此外，由于社会经济地位等混杂因子往往与环境暴露高度耦合，传统模型难以消除混杂偏倚（Confounding Bias），导致无法计算环境因子的因果效应；而缺乏先验约束的深度学习模型容易学习到违背因果逻辑的伪相关（Spurious Correlation）权重。针对上述混杂难以解耦，非线性交互建模缺失及学习伪相关权重的问题，本文提出了基于因果发现与超图学习的危险因素分析模型，以实现对“环境-基因”病因机制的定量分析。模型首先构建基于双流因果变分自编码器的解耦框架，将人口学特征、环境暴露特征及遗传特征作为输入，通过希尔伯特-施密特独立性准则（HSIC）强制环境暴露表征与潜在混杂表征（主要由人口学特征编码生成）在希尔伯特空间正交独立，从数学上消除变量间的伪相关；随后引入动态超图神经网络，将基因位点建模为节点，利用多头自注意力机制构建协同致病超边，并设计环境门控机制，将解耦后的环境暴露表征作为门控系数对超边特征进行非线性加权，模拟环境暴露作为促癌剂对基因致病风险的协同效应（Synergistic Effect）；最后构建融入医学知识先验的深度神经决策森林，引入医学知识库作为先验约束指导决策树生长，输出具有生物学解释性的肺癌因果图谱、致病决策路径及代理风险评分，为一级预防策略提供量化依据。

# （2）基于因果扩散模型的高危人群识别

现有的肺癌高危人群识别研究主要基于回顾性医疗数据，面临着严重的数据质量与偏差挑战。一方面，临床数据存在极大的数据异构性与时序稀疏性，离散的类别特征（如癌症分期、性别、吸烟状态等）与连续的生理指标混合，且因随访不连续导致关键数据缺失，传统判别式模型难以处理此类不规则采样数据；此外，传统模型往往忽视了肺癌与慢阻肺（COPD）等伴生疾病之间存在的共病模式，难以捕捉生理指标间协同演变的病理规律；另一方面，回顾性队列中普遍存在幸存者偏差，导致模型容易学习到如“吸烟保护效应”等违背因果逻辑的伪相关，限制了模型的可信度。针对数据异构稀疏、共病模式缺失及幸存者偏差误导等问题，本文提出基于因果扩散模型的高危人群识别方法，以实现对隐匿高危个体的精准锁定与动态风险预测。模型首先利用模拟比特编码（AnalogBits）技术将异构数据映射至连续欧氏空间，解决扩散模型无法直接处理非欧氏空间离散数据的难题；随后构建基于正交解耦机制的双重注意力骨干网络，在时间维度捕捉演变趋势，在特征维度捕捉肺癌与伴生疾病的共病模式，利用多维共病特征的协同互补增强时序表征能力；进一步设计基于因果约束的梯度引导机制，在扩散生成过程中利用因果判别器实时评估生成轨迹与环境暴露强度之间的时序一致性（Temporal Consistency），通过反向梯度强制修正伪相关偏差。最后，利用反事实推理模拟个体在不同干预条件下的完整纵向风险演变轨迹，实现对未来发病风险的纵向预测。

# (3) 基于因果解耦与神经符号推理的随访建议生成

现有的肺癌随访管理面临着“准入判定难”、“信息提取难”与“决策合规难”的多重困境。在准入阶段，电子病历中常包含“重度吸烟”等定性描述，难以匹配《指南》中“吸烟指数  $\geq 30$  包年”的定量标准；在信息处理阶段，影像报告多为非结构化文本，传统生成式模型因概率采样机制易产生“数值幻觉”（如混淆  $6\mathrm{mm}$  与  $8\mathrm{mm}$  的临界阈值）及长文本“注意力稀释”；在决策阶段，通用大模型缺乏严谨约束，易产生违背指南的逻辑断链。针对上述定性定量语义鸿沟、数值提取失真及决策不合规问题，本文提出了基于知识图谱与大语言模型的随访建议生成智能体。模型首先设计潜在语义特征交互机制，利用因果解耦技术从文本中提取“吸烟强度”与“持续时间”的潜在因子，通过哈达玛积进行交互运算，推断患者是否满足高危准入标准，解决定性描述与定量门槛不匹配的难题；随后引入基于事实库的高保真信息抽取架构，采用面向长文本的医疗预训练编码器与条件随机场构建包含实体跨度索引的中间层离散事实库，并利用指针网络执行拷贝机制，直接从原始文本中复制关键数值，从算法原理上切断生成式模型产生数值幻觉的路径，实现临床特征的高保真提取；最后构建神经符号临床推理智能体，建立临床决策状态图（CDSG），将《指南》转化为包含确定性状态节点与逻辑转移边的有向图谱，智能体采用“基于布尔逻辑的符号硬匹配”与“基于大语言模型的语义软匹配”相结合的策略，在图谱上执行路径约束推理，利用边条件严格校验逻辑路径，并基于完整推理轨迹进行模板槽位填充，输出包含“随访建议、推理链条、指南锚点”的标准化循证报告，实现全链路的逻辑闭环。

# （4）肺癌预防控制辅助决策平台

设计并实现肺癌预防控制辅助决策平台，在肺癌一级预防与二级预防阶段为公共卫生人员及临床医生提供分析结果，辅助决策者制定更科学的精准防控方案。该平台利用Vue.js、SpringBoot、MyBatis、Neo4j图数据库、Mysql数据库、Python（PyTorch）等技术进行平台研发。在平台管理方面，该平台具备用户管理、数据管理和系统管理三项功能；在业务功能方面，该平台依据癌症控制连续体框架，具备危险因素分析、高危人群识别和随访建议生成等核心功能。平台通过集成人口学、环境暴露及基因组学数据，利用因果发现与动态超图神经网络进行危险因素分析，在一级预防阶段分析环境-基因交互的非线性协同病因机制；通过融合纵向诊疗数据与共病模式特征，利用因果扩散模型与反事实推理进行高危人群识别，在二级预防筛查前精准锁定隐匿高危个体并推演其风险轨迹；通过解析非结构化电子病历与胸部CT影像报告，利用知识图谱与“符号-语义协同”机制的临床推理智能体进行随访建议生成，在二级预防管理阶段输出符合《指南》规范的标准化循证报告。在肺癌预防控制阶段实现全流程辅助决策，对提高病因解析深度、优化早期筛查资源配置以及规范全周期健康管理具有非常重要的现实意义。

# 3. 拟解决的关键性问题

(1) 构建多模态因果超图神经网络，利用因果解耦技术与环境门控机制，以解决多模态数据中强混杂偏倚难以剔除、“环境-基因”非线性协同病因机制难以建模及缺乏先验约束导致模型易学习伪相关权重的问题。

(2) 设计时序因果扩散生成模型, 结合因果约束的梯度引导与反事实推理机制, 以解决回顾性医疗数据异构稀疏、伴生疾病共病模式缺失及幸存者偏差导致模型不可信的问题。

(3) 构建神经符号临床推理智能体, 利用潜在语义交互与 “符号-语义协同” 推理机制, 以解决定性描述与定量标准存在语义鸿沟、生成式模型易产生数值幻觉及复杂指南执行逻辑断链的问题。

# 二、学位论文研究依据

# 1. 选题依据和研究意义

慢性非传染性疾病（NCDs）已成为严重威胁全球人类健康、阻碍国家经济社会发展的重大公共卫生问题。世界卫生组织（WHO）指出，NCDs导致的死亡占全球总死亡人数的 $74\%$ ，其中癌症是NCDs致死的主要原因之一[1]。而在所有癌症中，肺癌的发病率与死亡率长期居首，是NCDs防控中最为严峻的首要挑战，其防控成效直接关系到“健康中国”战略基石的稳固[2]。WHO明确指出，肺癌的病理演化是一个涉及环境暴露、遗传易感性与生活行为方式多因素交互的复杂长期过程[3]；《预防医学（第8版)》也强调了对这一复杂过程进行全方位干预的必要性[4]。在人口老龄化加剧与环境致病因素日益复杂的背景下，传统的以“终末期治疗”为重心的被动医疗模式，已难以遏制肺癌疾病负担的持续增长。

在此背景下，依据《预防医学》提出的“三级预防”策略[4]与美国国家癌症研究所（NCI）确立的癌症控制连续体（Cancer Control Continuum）框架[5]，构建覆盖全生命周期的精准防控体系势在必行。肺癌防控本质上是一项融合流行病学因果推断、临床诊疗逻辑与计算医学的复杂系统工程，其目标不应局限于确诊后的临床治疗，而应逐步转向“全流程、主动式”的精准决策范式[6]。这一范式要求在微观层面能更早识别环境-基因的病因机制，在宏观层面能动态推演个体风险演变轨迹并生成合规的干预策略，从而将“病因阻断（一级预防）、早诊早治（二级预防)”前移为常态化的智能决策能力。尤其在二级预防阶段，肺结节（Pulmonary Nodules）的科学管理是阻断其向浸润性肺癌转化的关键路径。研究表明，超过  $90\%$  的早期肺癌在影像上表现为肺结节，依据Lung-RADS或《中国肺癌筛查标准》对结节进行风险分层管理，能够显著降低肺癌死亡率[94]。随着《“健康中国2030”规划纲要》[7]的深入推进，防控决策的科学性、前瞻性与精准性被提出更高要求，亟需新技术手段支撑跨阶段协同与精细化治理。

尽管现有的肺癌筛查与管理体系不断完善，但在应对高度复杂且异构的真实世界医疗数据时，仍面临突出的“数据—机理—决策”转化瓶颈。其一，在病因分析层面，多模态数据间存在严重的“语义鸿沟”与“强混杂性”。环境暴露与基因组特征分散在不同维度，且社会经济地位等混杂因子往往掩盖了环境因子的真实致病效应，导致传统统计模型无法剥离混杂偏倚，从而产生大量的伪相关结论[8]。其二，在风险识别层面，医疗数据具有显著的“异构性”与“时序稀疏性”。回顾性队列中包含影像（连续）、文本（非结构化）等异构模态，且随访记录不连续；同时，现有模型往往忽视了肺癌与慢阻肺（COPD）等共病模式（Comorbidity）的关联，导致无法在非均匀采样的数据中精准刻画个体健康状态的纵向演变规律[9]。其三，在临床决策层面，决策过程缺乏“可解释性”与“合规性”约束。电子病历中的非结构化描述与《指南》定量标准之间存在匹配鸿沟[10]，通用大语言模型在缺乏医学逻辑约束时容易产生“数值幻觉”和逻辑断链，导致生成的随访建议违背临床指南规范[11]。

近年来人工智能技术的突破为缓解上述瓶颈提供了新路径。深度学习具备强大的非线性特征提取能力，能够在高维数据中识别复杂的风险模式[12]。然而，现有的医疗AI应用多侧重于统计关联挖掘，在应对肺癌防控的全流程复杂场景时仍显力不从心[13]。具体而言，纯数据驱动的模型缺乏对医学因果机制的显式建模，极易学习到数据分布中的虚假关联，在分布外数据（OOD）上泛化能力差[13]；现有判别式模型难以生成缺失的时序轨迹，无法回答“如果不干预，未来5年风险如何演变”的反事实问题，限制了对隐匿高危人群的动态预警能力[14]；且黑盒模型缺乏符号逻辑推理能力，无法将《指南》知识内化为决策约束，导致诊疗建议的可信度不足[15]。

在众多AI技术路线中，因果表征学习（Causal Representation Learning）因其天然适配“混杂解耦一机制发现一反事实推演”的认知逻辑，成为连接多源异构数据与医学病理机制的关键技术路径[13]。肺癌的发生发展可被视为一个复杂的因果动态过程，超图神经网络能够建模环境对基因的高阶协同作用，量化“促癌点火”的复杂病因机制[16]；因果扩散模型能够基于反事实逻辑生成连续的风险演变轨迹，解决数据稀疏与共病模式缺失问题[17]；而神经符号智能体则能通过逻辑约束实现符合指南的决策推理，确保决策合规[18]。这些技术的融合，为实现从“黑盒预测”到“白盒决策”的跨越提供了新的计算范式。

综上，本研究拟构建基于因果表征学习的肺癌预防控制辅助决策体系：以因果解耦技术剔除多模态数据中的混杂偏倚，利用超图学习量化环境-基因的非线性协同病因机制；引入因果扩散模型重建含共病模式的风险演变轨迹，解决数据异构与稀疏难题；并结合知识图谱约束的大语言模型实现合规的随访管理。本研究旨在打破数据孤岛，引入可解释的因果机制约束，从而提升肺癌危险因素分析的深度、高危人群识别的精度与随访建议生成的规范性，为公共卫生部门与临床医生提供可量化、可追溯、可落地的全流程决策支持。特别需要说明的是，本研究聚焦于符合《中国肺癌筛查标准》界定的高风险个体，即：年龄50-74岁，且吸烟指数  $\geq 30$  包年（或戒烟不足15年），以及具有肺癌家族史或职业暴露史的特定群体[95]。

# 2. 国内外研究现状和发展态势

针对目前国内外肺癌预防控制过程中的关键技术环节，本文将重点围绕危险因素分析、高危人群识别、随访建议生成以及肺癌防控辅助决策平台共四个方面进行阐述。

# 2.1危险因素分析研究现状

肺癌的发生是环境暴露（如吸烟、空气污染）与遗传易感性（如基因突变）之间复杂的交互结果，准确识别这种“基因-环境交互作用（Gene-Environment Interaction,  $\mathrm{G} \times \mathrm{E}$ ）”对于揭示肺癌的病因机制至关重要[19]。传统的流行病学研究多依赖广义线性模型（GLM），该类方法假设风险因素的效应是线性可加的，难以拟合生物学上客观存在的非线性协同机制（即“促癌”与“驱动”的复杂耦合）[20]；且环境暴露数据中往往隐含社会经济地位、职业暴露等强混杂因子，导致传统统计结果存在大量的伪相关[8]。

为了突破传统统计学方法的局限，研究人员开始引入人工智能技术。机器学习与深度学习凭借其强大的非线性映射能力，能够从高维组学数据中提取复杂的特征组合，为捕捉微效基因的累加效应提供了新路径[21]。然而，现有的数据驱动方法在提升预测精度的同时，也带来了模型“黑盒化”的问题。由于缺乏对医学因果逻辑的显式建模，模型往往倾向于拟合数据分布中的虚假关联，导致其在面对分布外数据（Out-of-Distribution, OOD）时泛化能力不足[13]。

根据 Eraslan 等人[21]与 Hunter[19]的综述分类，现有的危险因素分析方法主要分为四类：基于传统统计学与机器学习的方法、基于深度神经网络的方法、基于图网络学习的方法、以及基于因果推断与多模态融合的方法。

# （1）基于传统统计学与机器学习的方法

此类方法主要通过降维策略或集成学习框架，在有限样本下检测高维遗传与环境数据的交互作用。Ritchie等人[22]提出多因子降维法(MDR)。该方法不依赖遗传模式假设，通过将多位点基因型组合归纳为高风险或低风险类别以将高维数据降至一维。在乳腺癌研究中，MDR成功识别了一个包含COMT、CYP1A1、CYP1B1和GSTM1的四位点最佳交互模型，其交叉验证一致性达到10/10，证明了其检测高阶非线性交互的能力。Lou等人[23]提出广义多因子降维法(GMDR)。针对MDR只能处理离散数据的局限，GMDR引入了基于广义线性模型的评分统计量，允许在模型中对年龄、吸烟史等连续型协变量进行调整。模拟实验显示，在存在混杂因素的情况下，GMDR的统计功效（Power）比传统MDR提升了约  $25\%$  。Winham等人[24]将随机森林算法应用于交互分析。利用树结构自然的路径分裂能力来捕捉SNP间的非线性关系。在全基因组关联分析（GWAS）模拟中，该方法成功识别出了传统逻辑回归漏掉的纯上位效应，在20个致病位点的检测中达到了  $95\%$  的灵敏度。Park等人[25]提出惩罚逻辑回归模型。通过引入LASSO(L1)或Ridge(L2)正则化项约束回归系数，解决了高维组学数据中多重共线性导致的过拟合问题。该方法在实际癌症数据集中，有效筛选出了关键的基因-环境交互项，同时将假阳性率控制在较低水平。Moore等人[26]提出符号判别分析法。利用遗传规划自动进化出最佳区分病例与对照的数学表达式。该算法在膀胱癌研究中，成功识别出包含NAT2基因乙酰化状态与吸烟行为的最佳交互组合，构建了预测准确率显著优于线性判别分析的非线性模型。

# (2) 基于深度神经网络的方法

此类方法利用深层网络架构自动从高维组学数据中提取非线性特征，实现端到端的风险预测。Wang等人[27]提出一种结合生物学知识的深度学习模型(BK-CNN)。通过将基因表达数据根据通路信息映射为二维图像形式输入CNN，利用卷积核捕捉基因间的局部拓扑关系。在TCGA肺腺癌数据集上，该模型实现了0.7148的平均AUC，显著优于传统支持向量机（SVM）的0.6520，并成功识别出与生存期显著相关的关键通路。Zhou等人[28]提出基于深度学习的序列分析模型(DeepSEA)。该模型利用卷积神经网络直接从DNA序列中学习调控模体(Motif)特征，预测非编码区突变对转录因子结合及组蛋白修饰的影响。DeepSEA在大规模表观基因组数据上的预测AUC超过0.90，是解析非编码区变异致病机制的里程碑式工作。Chaudhary等人[29]提出基于自编码器的多组学集成框架(Deep Learning Multi-omics)。通过无监督预训练自编码器将DNA甲基化、miRNA和基因表达数据压缩到低维潜在空间，再连接Cox回归网络。该方法在肝癌数据集上的C-index达到0.76，并成功将患者划分为生存差异显著的两个亚组（Log-rank test  $\mathrm{P} < 0.001$  )。Katzman等人[30]提出基于深度神经网络的生存分析模型(DeepSurv)。该方法将Cox比例风险模型的线性部分替换为深度前馈神经网络，从而能够拟合协变量与风险之间的非线性关系。在多个癌症生存数据集的测试中，DeepSurv的一致性指数（C-index）显著优于标准Cox模型。Jie等人[31]提出流形正则化多任务特征学习框架(M2TFS)。利用深度神经网络提取特征，并引入流形正则化保持数据在局部空间的一致性，从海量基因数据中筛选出与疾病高度相关的标志物。实验表明，该方法在小样本数据集上的分类准确率比传统Lasso方法提升了  $8.4\%$  。

# （3）基于图学习的方法

此类方法将基因、蛋白质及环境因子建模为图中的节点，利用图拓扑结构捕捉生物分子间复杂的关联关系。Wang等人[32]提出MOGONET（Multi-omics Graph Convolutional Networks）。通过为DNA甲基化、mRNA表达和miRNA表达分别构建图网络，并利用视图相关性发现网络（VCDN）探索跨模态的高阶相关性。该算法在肺癌等多种癌症的分类任务中，平均准确率优于传统KNN和SVM方法约  $10\%$  ，证明了图结构在多组学整合中的有效性。Zitnik等人[33]提出Decagon模型。该模型构建了一个包含蛋白质-蛋白质相互作用和药物-靶点相互作用的大规模多模态图，利用图卷积网络预测多重用药的副作用。虽然该工作侧重于药物副作用，但其提出的多模态图卷积框架被广泛应用于后续的基因-环境交互网络建模中。Feng等人[16]提出超图神经网络(HGNN)。利用超边（Hyperedge）连接多个节点来表示复杂的非成对关系（如一个通路包含多个基因）。在生物网络分类任务中，HGNN能够有效捕捉多对多的高阶交互，其分类准确率比传统GCN提升了  $5.3\%$  。Nguyen等人[34]提出GraphDTA模型。该方法将药物分子建模为图结构，利用图神经网络（GNN）预测药物与靶点蛋白的结合亲和力。在Davis和Kiba数据集上，GraphDTA的均方误差(MSE)显著低于传统的基于序列的深度学习模型，为肺癌靶向药物筛选提供了高效工具。Parisot等人[35]提出基于谱图卷积的疾病预测模型(Spectral GCN)。通过利用表型信息（如年龄、性别）构建人群图(Population Graph)，将影像特征与非影像信息结合。该研究开创了利用GCN进行半监督疾病预测的先河，其提出的“人群图”概念被广泛应用于后续的肺癌风险分层研究中。

# (4) 基于因果推断与多模态融合的方法

此类方法旨在引入因果机制以消除混杂偏倚，并整合异构数据以提升模型的解释性与泛化能力。Mao等人[36]提出跨模态因果结构学习框架(CM-CSL)。通过在潜在表示空间引入结构方程模型（SEM）约束，强制模型学习解耦的因果因子。在合成医疗数据集上的实验显示，该方法因果发现的F1分数达到0.85，显著优于传统关联学习模型。Sanchez等人[14]提出反事实扩散模型。通过生成“健康状态”下的合成影像并与真实病灶影像对比，实现了病灶的因果定位。该算法在医学影像异常检测中的Dice系数达到了0.75以上，能够回答“如果该患者未患病，其影像应呈现何种状态”的反事实问题。Kyono等人[37]提出CASTLE正则化方法。在深度学习的损失函数中加入因果结构重构损失，迫使模型仅利用因果父节点进行预测，从而剔除混杂因子的干扰。实验表明，在存在强混杂的医疗数据集上，CASTLE的AUC比标准MLP提升了约  $6\%$  。Fasanelli等人[38]利用因果中介分析(Causal Mediation Analysis)研究了吸烟、DNA甲基化与肺癌之间的关系。通过分析来自四个前瞻性队列的数据，量化了甲基化在吸烟致癌路径中的中介效应，发现AHRR和F2RL3基因的低甲基化解释了约  $37\%$  的吸烟致癌风险。Louizos等人[39]提出因果效应变分自编码器(CEVAE)。该方法利用深度潜变量模型来估计干预后的因果效应，即便在存在隐混杂因子的情况下也能通过代理变量进行调整。在因果推断基准数据集IHDP上，CEVAE估计的平均治疗效应（ATE）误差显著低于传统回归方法，证明了深度生成模型在因果推断中的潜力。

# 2.2 高危人群识别研究现状

肺癌风险的演变在长期吸烟者及职业暴露人群中表现出显著的动态随机性[96],且经常伴随慢阻肺（COPD）、肺结核等共病模式，精准识别高危人群是实现二级预防的前提。然而，现有的筛查队列（如NLST、PLCO）与真实世界电子病历数据普遍存在“时序稀疏性”和“数据异构性”特征；且未确诊人群的健康轨迹往往缺失，构成了典型的数据偏差[9]。

传统的肺癌风险评估主要依赖基于Cox比例风险回归的统计学模型（如PLCOm2012）。此类方法通常仅利用患者的基线特征（如入组时的年龄、吸烟史）进行一次性静态评分，忽略了风险因素随时间的动态演变，导致对长期戒烟或病情波动人群的预测精度下降[41]。随着深度学习技术的突破，循环神经网络与Transformer架构被引入医疗时序分析。这些模型凭借强大的序列建模能力，能够捕捉疾病进展的长期依赖性，有效处理不规则采样数据，显著提升了风险预测的灵敏度[40]。

尽管时序深度学习模型在性能上超越了传统统计方法，但在公共卫生决策层面仍面临严峻挑战。现有的主流模型多为判别式模型，侧重于拟合观测数据的统计关联，缺乏对反事实结果的推演能力——即无法回答“如果该高危个体在一年前戒烟，现在的风险轨迹会有何不同？”的问题，限制了干预策略的制定[56]。此外，面对严重的共病记录缺失，现有模型多采用均值插补，破坏了数据原本的分布特征。因此，基于生成式AI与因果推断的方法正成为解决数据稀疏与反事实推演难题的新趋势。

根据 Shickel 等人[40]与 Eraslan 等人[21]的综述分类，现有的高危人群识别方法主要分为四类：基于传统统计学与机器学习的方法、基于循环神经网络的时序预测方法、基于注意力机制（Transformer）的序列建模方法、以及基于生成式与因果推断的方法。

# （1）基于传统统计学与机器学习的方法

此类方法多基于Cox比例风险回归或集成学习模型，利用基线特征进行静态风险评分，是目前临床筛查的“金标准”。Tammemägi等人[41]提出了著名的PLCOm2012模型。该模型基于前瞻性PLCO队列数据，纳入年龄、吸烟强度、BMI、家族史及COPD史等11个预测因子。在外部验证队列中，PLCOm2012的AUC达到0.81，显著优于仅基于年龄和吸烟史的USPSTF标准，被NCCN指南推荐用于确定肺癌筛查资格。Cassidy等人[42]提出了利物浦肺项目(LLP)风险模型。该模型重点考察了职业暴露（如石棉接触史）和恶性肿瘤家族史对风险的加权影响。在英国人群的验证中，LLP模型预测5年肺癌风险的AUC为0.71，为职业高暴露人群的筛选提供了量化依据。Hoggart等人[43]对欧洲多个队列（EPIC）进行了大规模验证，提出并比较了LLP与Spitz等风险模型。研究发现，虽然传统模型在特定人群中表现良好，但在跨国家、跨吸烟习惯的人群中泛化能力有限，且对变量随时间变化的动态效应拟合不足，强调了开发动态风险模型的必要性。Gould等人[44]提出基于逻辑回归的肺结节恶性概率评估模型。通过整合临床特征与CT影像的语义特征（如毛刺征），该模型在区分良恶性结节上的AUC达到0.79，解决了传统单一影像特征特异性不足的问题。Katzman等人[30]提出DeepSurv模型。DeepSurv将Cox比例风险模型的线性部分替换为深度前馈神经网络（MLP)，从而能够拟合协变量与风险之间的非线性关系。在多个癌症生存数据集上的C-index优于标准Cox回归约  $5\%$  证明了非线性特征交互对风险分层的重要性。

# （2）基于循环神经网络的方法

此类方法利用 LSTM 或 GRU 单元处理不规则时间序列，通过记忆门控机制捕捉疾病进展的长期依赖性。Choi 等人[45] 提出 DoctorAI。该模型利用门控循环单元（GRU）对电子病历中的诊断代码、用药记录和手术时间进行序列建模，预测患者下一次就诊的临床事件。在 Sutter Health 数据集上，Doctor AI 预测下一次诊断的准确率（Recall@30）达到  $79\%$ ，证明了 RNN 在捕捉纵向医疗轨迹方面的优势。Che 等人[46] 提出 GRU-D 模型。针对医疗时序数据中普遍存在的缺失值问题，GRU-D 引入了衰减机制（Decay Mechanism），根据上一次观测的时间间隔动态调整隐状态的权重。在 MIMIC-III 数据集的死亡率预测任务中，GRU-D 的 AUC 达到 0.85，显著优于采用均值插补的传统 LSTM。Lee 等人[47] 提出 DeepHit 模型。这是一个基于 RNN 的动态生存分析框架，专门设计用于处理竞争风险（Competing Risks，如死于肺癌 vs 死于心血管疾病）。该模型引入了特定于时间的生存分布损失函数，在多类竞争事件预测中的一致性指数比传统方法提升了  $3 - 5\%$ 。Du 等人[48] 提出递归标记点过程模型 (RMTPP)。该方法不仅预测“是否”患病，还预测“何时”患病，通过建模事件发生的时间强度函数，精确刻画了疾病随时间的演变速率。在医疗事件流预测中，RMTPP 的时间预测误差 (RMSE) 显著低于标准 RNN。Lipton 等人[49] 提出利用 LSTM 对多元临床时间序列进行多标签分类。该研究是早期将 LSTM 应用于处理包含大量缺失值和变长序列的临床诊断任务的代表作，其在 128 种疾病诊断分类任务上的 F1 分数显著优于强基准模型（如 MLP 和 Logistic 回归）。
# （3）基于注意力机制的方法

此类方法利用Transformer架构及其自注意力机制（Self-Attention）并行处理长序列，解决了RNN在长距离依赖上梯度消失的问题，并能更好地整合非结构化文本数据。Li等人[50]提出BEHRT模型。这是首个将BERT架构应用于电子病历的预训练模型，通过将疾病诊断映射为“单词”，将就诊记录映射为“句子”。在多项疾病预测任务中，BEHRT的平均精度均值（AP）比Deepr（基于CNN）和RETAIN（基于RNN）提升了  $8 - 10\%$  。Luo等人[51]提出HiTANet（Hierarchical Time-Aware Attention Network）。针对医疗事件具有显著的时间滞后性，该模型设计了层级时间感知注意力机制，分别捕捉局部就诊内和全局跨就诊的时间模式。在慢性病风险预测中，HiTANet的AUC达到了0.88。Rasmy等人[52]提出MedBERT。该模型在大规模结构化电子病历（超过2000万患者）上进行了预训练，通过掩码语言模型任务学习医学概念的上下文关联。实验显示，Med-BERT在少样本（Few-shot）场景下的糖尿病和癌症预测性能大幅提升，AUC提升幅度超过  $20\%$  。Gao等人[53]提出层级注意力网络(HAN)。该模型通过词级和句级两层注意力机制，从非结构化癌症病理报告中提取关键特征。在NCI-SEER队列数据上的实验显示，HAN在提取原发部位和组织学分级任务上的Micro-F1分数分别达到0.852和0.765，优于传统SVM和CNN。Ma等人[54]提出ConCARE模型。该模型利用序列动态图Transformer（Sequence-based Dynamic Graph Transformer）来捕捉医疗特征之间的显式高阶交互（High-order Interaction）以及时间依赖性。在MIMIC-III的死亡率预测任务中，ConCARE的AUPRC达到0.548，显著优于标准Transformer和GRU模型，证明了显式建模医学特征交互的必要性。

# (4) 基于生成式与因果推断的方法

此类方法旨在突破判别式模型的瓶颈，通过生成未来的疾病演变轨迹或推断反事实风险，解决回顾性数据稀疏与有偏的问题。Nagpal等人[55]提出深度生存机器(DeepSurvival Machines, DSM)。不同于传统Cox模型假设固定的风险形式，DSM利用生成式方法将生存时间分布建模为多个参数分布的混合。在多个医疗数据集上，DSM在长尾风险预测中的性能显著优于DeepSurv，能够精准捕捉不同风险亚群的生存模式。Bica等人[56]提出反事实循环网络 (CRN)。虽然常用于治疗效应估计，但其本质是构建随时间演变的反事实轨迹。在风险预测中，CRN能够回答“如果该高危个体未接受干预，其未来5年的肺癌风险轨迹如何演变”的问题，从而为识别隐匿高危人群提供了动态的因果基准。Ma等人[17]提出因果扩散模型 (DiffPO)。该模型利用扩散模型（Diffusion Models）的强大生成能力来学习潜在结果的分布。在具有复杂混杂的医疗数据中，DiffPO能够生成符合因果逻辑的患者未来健康状态，解决了传统模型在数据稀疏区域预测方差过大的问题。Alaa等人[57]提出深度多任务高斯过程 (Deep Multi-task Gaussian Processes, DMGP)。提出了一种基于高斯过程的非参数化贝叶斯模型，用于个体化生存分析。DMGP能够从纵向数据中学习不同任务（如不同共病人群）之间的相关性，从而在小样本或稀疏数据下实现高精度的风险预测。Richens等人[58]提出基于反事实因果推断的诊断模型。提出利用因果图构建反事实算法，通过模拟“如果我们消除了该症状，疾病是否仍存在”来区分相关性风险与因果性风险。在包含肺癌在内的复杂疾病诊断中，该方法的准确率排名第一，超越了传统的关联性AI模型。

# 2.3随访建议生成研究现状

筛查后的随访管理是肺癌防控闭环中的关键环节。肺结节是肺癌临床诊断的主要前驱特征，相关前瞻性研究指出，结节的大小（Size）、密度（Solid/Sub-solid）及倍增时间与恶性概率呈显著正相关[97]。因此，随访管理的本质是将这些影像学特征精准映射为肺癌风险等级。依据患者的风险分级与影像学表现（如结节大小、密度），严格遵循临床指南制定复查策略，是降低肺癌死亡率的核心措施[59]。然而，真实世界的电子病历多为非结构化文本，且存在大量模糊描述（如“部分实性结节”），难以直接匹配指南中的定量规则。传统的临床决策支持系统（Clinical Decision Support Systems，CDSS）主要依赖专家构建的“IF-THEN”规则库，这种方法维护成本极高，且在面对复杂、边界模糊的病例时缺乏泛化能力[60]。

随着自然语言处理（NLP）技术的进步，医疗AI从早期的信息提取逐渐向辅助决策演进。早期的深度学习模型主要通过监督分类将随访建议建模为多分类问题（如预测“3个月复查”或“活检”）。近年来，大语言模型（LLM）的出现引发了范式转移，其强大的语义理解与生成能力使得自动生成完整的、自然语言形式的诊疗建议成为可能[61]。然而，LLM在严肃医疗场景下仍面临严重的“幻觉”风险（如捏造指南条款）以及逻辑不可解释性。因此，结合符号逻辑（Symbolic Logic）与神经网络（Neural Networks）的神经符号人工智能（Neuro-symbolic AI）与智能体（Agent）技术，正成为构建可信赖、可审计的随访决策系统的前沿方向[62]。

根据 Thirunavukarasu 等人[61]与 Pan 等人[63]的综述分类，现有的随访建议生成方法主要分为四类：基于监督学习的分类推荐方法、基于知识图谱的推理决策方法、基于大语言模型的生成方法、以及基于神经符号与智能体的方法。

# （1）基于监督学习的分类推荐方法

此类方法将“生成建议”简化为“分类问题”，利用深度学习模型（如CNN,LSTM,BERT）对病历特征进行编码，预测预定义的随访类别或治疗方案。Coudray等人[64]提出基于深度学习的肺癌分类与突变预测模型。利用Inception v3架构对肺癌组织病理学切片进行分类，并预测随访治疗关键的驱动基因突变（如EGFR）。该模型在LUAD/LUSC分类任务上的AUC达到0.97，为精准随访方案的制定提供了可靠的病理学依据。Huang等人[65]提出ClinicalBERT。该模型在MIMIC-III临床笔记上预训练了BERT模型，用于预测患者的再入院风险（Readmission Prediction）。虽然不直接生成文本，但其生成的风险概率可直接转化为“高危需密切随访”的决策信号，其ROC-AUC比传统BERT提升了0.04。Qiu等人[66]提出基于深度学习的癌症病理信息提取网络。利用CNN对病理报告进行文本分类，自动提取原发部位和组织学分级。该方法在NCI-SEER数据集上的Micro-F1分数达到0.85，解决了随访决策中关键特征结构化的难题。Sheikhalishahi等人[67]综述了基于机器学习的临床决策推荐系统。研究指出，基于LSTM和CNN的监督模型在处理时序生命体征数据以推荐干预措施（如药物调整）方面表现优异，但缺乏对非结构化文本中复杂语境（如医生否定的排除诊断）的理解能力。Esteva等人[68]在Nature Medicine发表综述，指出深度学习在皮肤癌、肺癌等领域的分类能力已达到专家水平，目前的瓶颈在于如何将分类结果转化为符合指南的行动建议。

# (2) 基于知识图谱的推理决策方法

此类方法构建医学知识图谱（KG），利用路径搜索或图嵌入技术，根据患者实体在图谱中的位置推理出随访路径，具有较强的逻辑可解释性。Rotmensch等人[69]提出从电子病历自动构建健康知识图谱的方法。该图谱利用因果概率模型捕捉了症状与疾病、诊断与后续检查之间的关联。在肺癌诊断推理中，该图谱能够根据现有症状推荐下一步最可能的检查项目，起到了动态随访决策的作用。Wang等人[70]提出KGCN（Knowledge Graph Convolutional Networks）。该模型利用图卷积网络聚合知识图谱中的邻居信息（如药物相互作用、禁忌症）。在医疗推荐场景中，KGCN能够有效利用图谱结构信息规避潜在的用药风险，其推荐准确率显著优于仅利用用户-项目交互的基线模型。Shang等人[71]提出GAMENet。该模型结合了电子病历图与药物知识图谱，利用图增强记忆网络（Graph Augmented Memory Networks）进行用药推荐。在MIMIC-III数据集上，GAMENet推荐的药物组合在安全性（DDI rate）和准确性（Jaccard）上均优于现有方法，展示了KG在复杂决策中的约束作用。Beam等人[72]提出Clinical Concept Embeddings。通过在massive clinical corpora（如CUIMC数据）上学习医学概念的向量表示（Cui2Vec），模型能够理解“磨玻璃结节”与“肺腺癌”在语义空间上的距离，从而在没有大量标注数据的情况下，通过相似度检索推荐相似病例的随访方案。Choi等人[73]提出GRAM（Graph-based Attention Model）。该模型利用医学本体库（如ICD-9树形结构）作为先验知识，利用注意力机制将特定诊断代码映射为图谱中的祖先节点表示。在数据稀疏的罕见病预测中，GRAM利用知识图谱的层级结构弥补了样本不足，预测准确率提升了  $10\%$

# （3）基于大语言模型的生成方法

此类方法利用GPT-4、Med-PaLM等大模型，通过提示工程（Prompt Engineering）直接根据病历生成自然语言形式的随访建议和解释。Singhal等人[74]提出了Med-PaLM。这是首个在MedQA等医学问答数据集上达到“专家级”表现的大模型。通过指令微调（Instruction Tuning），Med-PaLM在生成肺癌治疗方案建议时，准确率达到了  $92.6\%$  ，且生成的文本逻辑通顺、语气专业。Kung等人[75]评估了ChatGPT在肿瘤学指南一致性上的表现。研究发现，ChatGPT在回答NCCN肺癌筛查指南相关问题时，总体准确率约为  $85\%$  。它能够生成详尽的随访建议解释，但在涉及极其具体的数值阈值（如结节直径  $6\mathrm{mm}$  vs  $8\mathrm{mm}$ ）时，仍偶发性地产生幻觉。Nori等人[76]评估了GPT-4在医学挑战问题上的能力。研究发现，GPT-4在USMLE考试中的表现显著优于GPT-3.5，且能够解释复杂的临床案例。然而，报告也指出，GPT-4在生成建议时偶尔会编造不存在的参考文献，这在严肃医疗决策中是不可接受的。Jeblick等人[77]研究了利用ChatGPT简化放射学报告并生成随访摘要。结果显示，LLM能够将晦涩的肺部CT报告转化为患者易懂的通俗语言建议，且事实一致性（Factual Consistency）较高，有效辅助了医患沟通环节。Liu等人[78]提出DeID-GPT。针对LLM应用中的隐私泄露问题，该研究设计了一种生成式框架，在保留医疗语义的前提下自动去除病历中的敏感信息（PHI）。实验显示，该方法在保证下游随访建议生成质量的同时，几乎完全消除了隐私泄露风险。

# （4）基于神经符号与智能体的方法

此类方法是当前的最前沿方向，即神经符号人工智能（Neuro-symbolic AI）与智能体（Agents）技术，旨在融合LLM的语言能力与KG/工具的逻辑能力，解决幻觉问题并实现可审计的合规决策。Tschandl等人[79]提出一种神经符号AI框架用于医疗报告处理。该框架利用深度学习提取特征，利用符号逻辑规则生成诊断建议。在皮肤癌和肺癌诊断任务中，该方法不仅准确率达到专家水平，还确保了决策过程的每一步都可追溯、可审计。Zakka等人[80]提出Almanac。这是一个检索增强生成（RAG）智能体，专门用于临床医学。Almanac不直接依赖LLM的内部参数知识，而是作为一个智能体去实时检索权威数据库（如BMJ Best Practice），并将检索到的指南片段作为上下文输入LLM生成建议。该方法将幻觉率从GPT-4的  $17\%$  降低到了  $2\%$  以下。Tang等人[81]提出MedAgents。这是一个基于多智能体协作（Multi-Agent Collaboration）的临床推理框架。针对复杂病例，MedAgents通过让LLM扮演不同领域的专家（如肿瘤学家、放射学家）进行“自我辩论”和“同行评审”，最终生成的建议比零样本提示（Zero-shot）的准确率提升了  $15\%$  。Wei等人[82]提出Chain-of-Thought (CoT)提示方法。虽然是通用方法，但在医疗推理中至关重要。通过引导模型生成“推理步骤”而非直接给出答案，CoT显著提升了模型在复杂诊疗路径（如：症状  $\rightharpoondown$  检查  $\rightharpoondown$  诊断  $\rightharpoondown$  随访）上的逻辑连贯性。Bai等人[83]提出Constitutional AI。研究提出了一套基于规则（Constitution）的约束框架，通过强化学习（RLAIF）确保智能体生成的建议符合预设的伦理和安全规范（如“无害性”），防止AI给出激进或违规的医疗建议。

# 2.4肺癌预防控制辅助决策平台研究现状

肺癌的预防控制是一项涉及多源数据融合与跨部门协同的复杂系统工程。在《“健康中国2030”规划纲要》的指导下，构建集监测预警、风险评估与干预决策于一体的智能平台，是实现癌症防控关口前移的关键载体。然而，目前的癌症防控平台大多呈现“功能割裂”状态：公共卫生系统侧重于宏观统计，缺乏个体层面的精准画像；临床诊疗系统侧重于确诊后的方案推荐，忽视了筛查与预防环节；而政策仿真模型虽然能推演干预效果，但计算复杂度极高，难以在实际业务中实时部署。根据功能定位与服务对象的不同，现有的肺癌防控相关平台主要可分为三类：基于人群的癌症登记与监测系统、基于循证医学的临床决策支持系统、以及基于计算流行病学的政策仿真平台。

# （1）基于人群的癌症登记与监测系统

此类平台由政府主导，旨在监测区域或国家层面的癌症发病率、死亡率及生存率趋势，为卫生政策制定提供宏观依据。Cronin等人[84]介绍了美国国家癌症研究所（NCI）建立的SEER（Surveillance, Epidemiology, and End Results）项目。作为全球最权威的癌症数据库之一，SEER覆盖了美国约  $48\%$  的人口，提供了详尽的癌症发病与生存统计数据。然而，SEER主要基于回顾性的病理登记数据，存在2-3年的数据滞后，难以满足实时风险预警的需求。Wei等人[85]详细阐述了中国国家癌症中心建立的国家癌症登记系统（NCCR）。该系统整合了全国数百个登记处的数据，实现了对中国肺癌疾病负担的动态监测。但目前该系统主要侧重于“结果监测”（如发病数），缺乏对环境暴露、吸烟行为等“过程数据”的整合，限制了其在病因追溯与一级预防中的应用。

# (2) 基于循证医学的临床决策支持系统

此类平台服务于临床医生，利用AI技术辅助肺癌的诊断分期与治疗方案制定。Liu等人[86]评估了IBM Watson for Oncology在中国肺癌患者治疗决策中的可行性。这项针对中国患者的实证研究显示，Watson推荐的治疗方案与中国三甲医院多学科专家团队（MDT）的一致性仅为  $65.8\%$  。这种差异主要源于Watson系统缺乏对中国本土化临床指南的适配，且在处理复杂的IV期肺癌及并发症时表现不佳。这一结果深刻揭示了直接引进国外“黑盒”决策系统在实际应用中的局限性，凸显了研发适应中国国情、具有可解释性的辅助决策平台的必要性。

# (3) 基于计算流行病学的政策仿真平台

此类平台利用数学模型模拟不同干预策略（如禁烟令、筛查覆盖率）对肺癌死亡率的长期影响。Meza等人[87]介绍了CISNET（Cancer Intervention and Surveillance Modeling Network）肺癌工作组的模型体系。通过整合吸烟史生成器、剂量-反应模块与筛查灵敏度模型，CISNET成功评估了美国NLST筛查试验的成本效益，直接推动了美国预防服务工作组（USPSTF）更新肺癌筛查指南。然而，CISNET模型是基于群体平均参数构建的，计算极其耗时，主要服务于宏观政策制定，难以直接用于个体层面的实时辅助决策。

综上所述，虽然国内外在癌症监测、临床辅助与政策仿真方面均已建立较为成熟的系统，但仍缺乏一个集成化、全流程的肺癌预防控制辅助决策平台。现有平台普遍存在“数据孤岛”（疾控数据与临床数据不互通）、“机理缺失”（重统计关联轻因果机制）以及“决策断链”（预测风险后缺乏可落地的干预建议）等问题。

# 3. 已有成果

无

# 4. 主要参考文献





# 三、学位论文研究计划及预期目标


# 3.1 主要理论

肺癌预防控制涉及病因分析、风险预测及随访管理等多个环节，其控制水平直接影响防控成效。其中，病因分析旨在识别环境暴露与遗传因子等危险因素的交互作用，为一级预防提供证据支撑；风险预测通过评估个体发病概率，辅助识别高危人群；随访管理则是依据临床指南对基线及年度筛查得到的肺结节检查结果进行随访管理，推动筛查结果的系统监控。

# 3.2 研究方法

因果发现技术是通过挖掘异构数据间的独立性与结构化关联，实现对潜在致病路径进行分析的方法。在肺癌病因研究中，由于环境暴露与基因特征具有高维及强噪声特征，适合采用基于希尔伯特-施密特独立性准则（HSIC）的解耦方法分离暴露因素与混杂因子；针对基因组的复杂交互，利用动态超图学习可以描述由多个基因构成的协同致病结构。

生成式因果建模是在因果框架下模拟不同条件下潜在结局分布的方法。由于真实世界肺癌筛查数据存在非规则采样与缺失值问题，适合使用因果扩散模型学习风险演变的连续分布；通过引入因果约束的梯度引导，可模拟受试者在改变环境暴露后的风险变化轨迹。

知识图谱与大语言模型是融合医学先验知识与语言处理能力的混合方法。肺结节随访建议生成需要兼顾非结构化病历理解与复杂指南规则遵循，适合使用知识图谱约束的大语言模型架构；通过将临床指南转化为决策状态图，可以引导模型在合规的逻辑路径上运行，实现随访方案的精确生成。

本文进一步在上述技术基础上引入正交解耦注意力机制与符号逻辑约束等模块。在研究过程中，通过控制变量法选择模型的关键超参数，并通过实验法对比多种基准模型，以验证本文方法的有效性与可靠性。

# 3.3 技术路线

# 3.3.2基于因果扩散模型的高危人群识别

针对肺癌风险预测中存在的“数据异构性”、“时空稀疏性”及“因果一致性缺失”三大核心挑战，提出基于因果扩散模型的高危人群识别模型（Causal-TabDiff）。Causal-TabDiff 模型旨在建立从异构历史观测序列到未来连续风险轨迹的生成映射。系统总体架构如图 5 所示，主要包含四个紧密耦合的核心模块：（1）统一输入表征模块（图 5-A）。利用模拟比特编码技术与高斯分位数变换将异构数据映射至连续欧氏空间，解决扩散模型无法直接处理非欧氏空间离散数据的难题。（2）机理一致性势能函数构建（图 5-B）。利用上游因果表征构建机理一致性势能函数，实时评估生成轨迹与环境暴露强度之间的时序一致性，为生成过程提供医学逻辑约束目标。（3）正交解耦去噪骨干（图 5-C）。构建基于正交解耦机制的双重注意力骨干网络，在时间维度捕捉演变趋势，在特征维度捕捉肺癌与伴生疾病的共病模式，利用多维共病特征的协同互补增强时序表征能力。（4）因果约束梯度引导采样（图 5-D）。设计基于因果约束的梯度引导机制，在扩散生成过程中通过反向梯度强制修正伪相关偏差，利用反事实推理模拟个体在不同干预条件下的完整纵向风险演变轨迹。


![[图5.png]]

图5.Causal-TabDiff：基于因果扩散模型的高危人群识别模型总体架构图


# 模块一：连续型偏向随机初始化

针对医疗表格数据  $\mathbf{X} \in \mathbb{R}^{N \times T \times D}$  （其中  $N$  表示受试者样本量， $T$  表示纵向随访时间步数， $D$  表示临床特征总维度）中连续变量与离散变量难以在单一高斯空间联合扩散的难题，本模块构建统一连续表征。

![[图6.png]]



图6. 异构特征的模拟比特编码与统一表征架构图


# 步骤一：连续特征的高斯分位数变换

对于连续型生理特征  $x_{num}$  （如BMI、FEV1），其原始分布往往呈现显著的偏态分布（Skewed Distribution）且不规则。为适配扩散模型的标准高斯先验，本研究引入高斯分位数变换（Gaussian Quantile Transformation）。公式定义如下：

$$
\tilde {x} _ {n u m} = \Phi^ {- 1} \left(F _ {e m p} \left(x _ {n u m}\right)\right) \tag {25}
$$

其中  $F_{emp}(x_{num})$  是经验累积分布函数（Empirical CDF），将原始数据映射到  $[0,1]$  的均匀分布区间，消除量纲差异。 $\Phi^{-1}(\cdot)$  是标准正态分布的逆累积函数（Probit function），将  $[0,1]$  区间的值拉伸至  $(-\infty, +\infty)$ ，强制使其服从  $\mathcal{N}(0,1)$ 。该变换消除了不同生理指标（如体重 vs 肺活量）间的数量级差异，并修正了数据的偏态特性，为神经网络提供了同分布的输入。

# 步骤二：离散特征的模拟比特流形映射

对于离散型临床特征  $x_{\text{cat}}$ （如癌症分期，设类别数为  $K$ ），传统 One-hot 编码在欧氏空间中稀疏且正交，直接施加高斯噪声会导致“去噪歧义”。本研究引入 Chen 等人提出的模拟比特编码策略[89]，将其嵌入至超立方体流形。

# （1）二进制量化

首先将类别索引转换为  $m = \lceil \log_2 K \rceil$  位的二进制向量  $\mathbf{b} \in \{0,1\}^m$ 。

# （2）模拟位映射

将离散的  $\{0,1\}$  映射为连续实数区间上的双极性坐标：

$$
\boldsymbol {x} _ {\text {a n a l o g}} = 2 \boldsymbol {b} - 1 \in \{- 1, 1 \} ^ {m} \tag {26}
$$

其中b是离散的二进制向量（如[1,0]）。2b-1是线性变换，将0映射为-1.0，1映射为+1.0。此时，离散类别被映射为  $\mathbb{R}^m$  维欧氏空间中一个超立方体（Hypercube）的顶点。例如，类别A对应(-1,-1)，类别B对应(-1,1)。这种几何结构使得离散数据可以像连续坐标一样添加高斯噪声（例如点漂移到(-0.8,1.2))，而去噪网络只需学习将其拉回最近的顶点即可。

# 步骤三：条件注入与统一张量构建

最终，将变换后的连续特征、模拟比特特征以及上游（Q1）传入的因果条件向量  $\pmb{c}$  进行拼接，形成统一输入张量  $X_{input}$ ：

$$
\boldsymbol {X} _ {\text {i n p u t}} = \operatorname {C o n c a t} \left(\tilde {\boldsymbol {x}} _ {\text {n u m}}, \boldsymbol {x} _ {\text {a n a l o g}} ^ {(1)}, \dots , \boldsymbol {x} _ {\text {a n a l o g}} ^ {(C)}\right) \oplus \operatorname {M L P} (\boldsymbol {c}) \in \mathbb {R} ^ {T \times D ^ {\prime}} \tag {27}
$$

其中Concat(...)是特征拼接操作。  $\oplus$  MLP(c)是因果条件向量  $\mathbf{c} = \{\alpha ,\mathbf{h}_{G\times E}\}$  （包含环境促癌强度  $\alpha$  与基因-环境交互嵌入  $\mathbf{h}_{G\times E}$  ）经过MLP映射后，以全局偏置的形式叠加到输入特征上，作为初始的条件引导。  $D^{\prime}$  是编码后的总特征维度。

# 模块二、正交解耦的双重注意力纵向骨干

为解决PLCO数据中普遍存在的随访中断（时间维度稀疏）与多病共存（特征维度耦合），本模块设计了正交解耦的双重注意力骨干网络（Orthogonal Dual-Attention Backbone）。该网络采用Pre-AdaGN结构，在每一层内部显式分离时间与特征的信息流，其微观数据流向如图7所示。

![[图7.png]]


图7. 正交解耦双重注意力骨干微观结构图


# 步骤一：时序演变重构

设第  $l$  层的输入隐状态为  $\mathbf{H}_{in}^{(l)} \in \mathbb{R}^{B \times T \times D'}$  。首先，数据流经第一个自适应群归一化层（AdaGN-1），随后进入时间注意力模块。

# (1) 自适应条件注入

利用因果条件向量  $\mathbf{c}$  对输入特征  $\mathbf{H}_{in}^{(l)}$  进行动态仿射变换，以注入环境与基因的交互信息：

$$
\widetilde {\boldsymbol {H}} _ {1} = \operatorname {A d a G N} _ {1} \left(\boldsymbol {H} _ {i n} ^ {(l)}, \boldsymbol {c}\right) = \gamma_ {1} (\boldsymbol {c}) \cdot \frac {\boldsymbol {H} _ {i n} ^ {(l)} - \mu}{\sigma} + \beta_ {1} (\boldsymbol {c}) \tag {28}
$$

其中  $\mu, \sigma$  是当前 mini-batch 的均值与方差。 $\gamma_1(\mathbf{c}), \beta_1(\mathbf{c})$  是由因果条件  $\mathbf{c}$ （含  $\alpha$  和  $\mathbf{h}_{G \times E}$ ）经过 MLP 生成的仿射变换参数。在处理时间序列之前，根据环境促癌强度与基因交互特征动态调整特征分布，模拟不同暴露水平下病程演变的基线差异。

# (2) 纵向时间注意力

将  $\widetilde{\mathbf{H}}_{1}$  沿特征维度切片，对每个特征独立计算时间轴上的自注意力：

$$
\boldsymbol {H} _ {\text {t e m p}} = \operatorname {S o f t m a x} \left(\frac {\boldsymbol {Q} _ {t} \boldsymbol {K} _ {t} ^ {T}}{\sqrt {d _ {k}}}\right) \boldsymbol {V} _ {t} + \boldsymbol {H} _ {\text {i n}} ^ {(l)} \tag {29}
$$

其中  $\mathbf{Q}_t, \mathbf{K}_t, \mathbf{V}_t$  仅在时间维度  $T \times T$  上进行投影与运算。该机制聚合历史观测点（如  $T_0, T_2$ ）的信息，跨越时间断层填补缺失值  $(T_1)$ ，捕捉单一指标（如 FEV1）随时间的纵向演变趋势。

# 步骤二：维度变换

为了捕捉不同特征之间的共病关系（例如吸烟量如何影响肺阻塞COPD），需要从“时间视角”切换到“特征视角”。由于标准注意力机制（Self-Attention）通常作用于张量的倒数第二个维度（即序列长度维），需要对张量进行转置操作（Permutation）：

$$
\boldsymbol {H} _ {\text {t r a n s}} = \operatorname {P e r m u t e} \left(\boldsymbol {H} _ {\text {t e m p}}\right) \in \mathbb {R} ^ {B \times D ^ {\prime} \times T} \tag {30}
$$

将特征维度  $D^{\prime}$  交换至序列维度，而将时间维度  $T$  移至批次维度。对于变换前 $(B,T,D^{\prime})$  ，注意力机制视  $T$  为序列长度，计算时间步之间的关联。对于变换后  $(B,D^{\prime},T)$  ，注意力机制视  $D^{\prime}$  为序列长度，计算特征之间的关联。这一操作是实现“时空正交解耦”的关键步骤，使得同一套注意力算法能复用于两个完全不同的维度。

# 步骤三：共病交互重构

数据流经第二个自适应群归一化层（AdaGN-2），随后进入特征注意力模块。

# (1) 二次条件注入

在进行特征维度交互之前，需再次利用因果条件c对特征进行归一化和调制。这步操作至关重要，因为环境促癌因子（ $\alpha$ ）不仅影响病程快慢，还会改变并发症之间的关联强度（例如：在极高污染暴露下，肺功能下降与炎症指标的共现概率会显著增加）。

$$
\widetilde {\boldsymbol {H}} _ {2} = \operatorname {A d a G N} _ {2} \left(\boldsymbol {H} _ {\text {t r a n s}}, \boldsymbol {c}\right) \tag {31}
$$

通过引入  $\mathrm{AdaGN}_2$  ，模型能够根据个体的因果背景（c），动态调整特征交互矩阵的分布，从而模拟不同风险背景下的特异性共病模式。

# (2) 横向特征注意力

将  $\tilde{\mathbf{H}}_{2}$  沿时间维度切片, 对每个时间步独立计算特征轴上的自注意力:

$$
\boldsymbol {H} _ {\text {f e a t}} = \operatorname {S o f t m a x} \left(\frac {\boldsymbol {Q} _ {f} \boldsymbol {K} _ {f} ^ {T}}{\sqrt {d _ {k}}}\right) \boldsymbol {V} _ {f} + \boldsymbol {H} _ {\text {t r a n s}} \tag {32}
$$

其中  $\mathbf{Q}_f = \widetilde{\mathbf{H}}_2\mathbf{W}_{Q_f}, \mathbf{K}_f = \widetilde{\mathbf{H}}_2\mathbf{W}_{K_f}, \mathbf{V}_f = \widetilde{\mathbf{H}}_2\mathbf{W}_{V_f}^{/a_k}$ , 查询、键、值矩阵由特征  $\widetilde{\mathbf{H}}_2$  经可学习的权重矩阵  $\mathbf{W}$  投影生成。 $\mathbf{H}_{trans}$  是维度变换后的特征。上述公式旨在捕捉同一时刻下不同临床指标间的病理依赖（如“BMI下降”与“癌症分期上升”的共现），利用共病机制辅助推断隐缺失值。

步骤四：输出融合

最后，将张量转置回原始形状，并通过前馈神经网络（FFN）进行非线性融合，得到当前层的输出：

$$
\boldsymbol {H} _ {\text {o u t}} ^ {(l)} = \operatorname {F F N} \left(\operatorname {P e r m u t e} ^ {- 1} \left(\boldsymbol {H} _ {\text {f e a t}}\right)\right) \tag {33}
$$

# 模块三、基于因果约束的梯度引导

这是本方案的核心创新。针对纯数据驱动模型易产生“幸存者偏差幻觉”的问题，本模块引入反事实约束，构建了一个“生成-评估-纠偏”的闭环反馈引导框架。

![[图8.png]]


图8.基于LSTM判别器的因果约束引导与梯度回传控制回路示意图


# 步骤一：初始噪声采样

生成过程始于标准高斯噪声分布，这代表了逆向生成过程的起点。对于预测未来  $T_{pred}$  年的轨迹，从各向同性高斯分布中采样：

$$
\boldsymbol {x} _ {T} \sim \mathcal {N} (\boldsymbol {0}, \boldsymbol {I}) \tag {34}
$$

其中  $\mathbf{x}_T$  是扩散过程的起始点（反向扩散的第  $T$  步），此时数据完全由噪声构成，包含最大的不确定性。 $\mathcal{N}(0,1)$  是均值为 0，协方差为单位矩阵的标准正态分布。初始噪声采样为生成模型提供了一个随机的“画布”。由于扩散模型本质上是从噪声中还原数据，每一次不同的随机采样都可能引导出一条略有差异的轨迹，这赋予了模型生成多样化且概率性结果的能力，能够覆盖未来可能的多种演变路径。

# 步骤二：机理一致性势能函数

为了评估生成轨迹是否符合因果逻辑，本研究预训练一个 LSTM 判别器  $f_{\phi}$  （如图 5-B）。LSTM 利用其长短期记忆单元（Cell State）捕捉累积暴露效应，预测当前轨迹对应的潜在环境促癌系数  $\hat{\alpha}$  。势能函数  $U(\mathbf{x}_t)$  被定义为预测系数与真实因果条件  $\alpha_{target}$  之间的欧氏距离：

$$
U \left(\boldsymbol {x} _ {t}\right) = \| f _ {\phi} \left(\boldsymbol {x} _ {t}\right) - \alpha_ {\text {t a r g e t}} \| ^ {2} \tag {35}
$$

其中  $f_{\phi}(\mathbf{x}_t)$  表示判别器网络基于当前生成的中间态轨迹  $\mathbf{x}_t$ ，反推出来的“该轨迹所属人群的风险系数”。 $\alpha_{target}$  是从 Q1 上游输入的真实环境促癌强度（Ground Truth）。 $\|\cdot\|^2$  是 L2 范数（平方误差），用于量化两者之间的偏差。该函数构建了一个高维空间中的“能量场（Energy Landscape）”。若生成轨迹显示“肺功能优异”但输入的  $\alpha_{target}$  为高风险（0.9），则偏差  $\left|f_{\phi} - \alpha_{target}\right|$  很大，导致势能  $U$  很高。系统的优化目标就是寻找一条路径，使得轨迹“流向”势能最低的区域（即机理一致区）。

# 步骤三：反向扩散与均值预测

在反向去噪的每一步  $t \to t - 1$ ，骨干网络首先预测当前时刻应该去除的噪声  $\epsilon_{\theta}(\mathbf{x}_t, t)$ 。根据Ho等人的推导[90]，预测噪声在数学上严格等价于预测后验分布  $p(\mathbf{x}_{t-1}|\mathbf{x}_t)$  的均值  $\mu_{\theta}$ 。其重参数化公式为：

$$
\boldsymbol {\mu} _ {\theta} \left(\boldsymbol {x} _ {t}\right) = \frac {1}{\sqrt {\alpha_ {t}}} \left(\boldsymbol {x} _ {t} - \frac {\beta_ {t}}{\sqrt {1 - \bar {\alpha} _ {t}}} \boldsymbol {\epsilon} _ {\theta} \left(\boldsymbol {x} _ {t}, t\right)\right) \tag {36}
$$

其中  $\mathbf{x}_t$  是当前时刻的含噪轨迹。 $\epsilon_\theta(\mathbf{x}_t, t)$  是骨干网络输出的预测噪声。 $\alpha_t, \beta_t, \bar{\alpha}_t$  是预设的扩散调度参数。其中  $\beta_t \in (0,1)$  为方差调度， $\alpha_t = 1 - \beta_t$ ， $\bar{\alpha}_t := \prod_{s=1}^t \alpha_s$  为  $\alpha$  的累乘积。该公式是通过最小化变分下界（ELBO）推导得出的。它表明，如果能准确预测加入的噪声  $\epsilon_\theta$ ，则能通过简单的线性变换，从  $\mathbf{x}_t$  中“减去”这部分噪声，从而估计出上一时刻的均值  $\mu_\theta$ 。这是模型在没有因果干预下的“自然演化方向”。

# 步骤四：梯度引导采样

为了将轨迹推向“低势能(符合因果)”区域, 需计算势能函数关于当前轨迹的梯度  $\nabla_{\mathbf{x}_t} U$ , 并将其反向施加于均值上:

$$
\boldsymbol {x} _ {t - 1} = \boldsymbol {\mu} _ {\theta} (\boldsymbol {x} _ {t}) - s \cdot \sigma_ {t} \cdot \nabla_ {\boldsymbol {x} _ {t}} U (\boldsymbol {x} _ {t}) + \sigma_ {t} \boldsymbol {z} \tag {37}
$$

其中  $\pmb{\mu}_{\theta}(\mathbf{x}_t)$  是由步骤三计算出的基础去噪均值，代表数据分布的拟合方向。  $-\nabla_{\mathbf{x}_t}U(\mathbf{x}_t)$  是势能函数的负梯度方向。在数学上，负梯度指向函数值下降最快的方向。因此，沿着这个方向移动  $\mathbf{x}_t$  ，可以最快地降低势能  $U$  ，即让轨迹变得更符合因果逻辑。  $s$  是制导强度（Guidance Scale），这是一个超参数。  $s$  越大，模型越倾向于服从医学规则；  $s$  越小，模型越倾向于自由生成。  $\sigma_t\mathbf{z}$  是随机噪声项，  $\mathbf{z}\sim \mathcal{N}(\mathbf{0},\mathbf{I})$  。随机噪声项保证了生成过程的多样性，防止轨迹坍缩为单一确定的解。动力学梯度制导采样实现了一个“推拉机制”。骨干网络想把轨迹拉向“像真实数据”的地方，而因果控制器想把轨迹拉向“符合环境  $\alpha$  设定”的地方。最终生成的轨迹是这两股力量平衡的结果，既真实又合理。

# 步骤五：解码器与最终输出

当扩散过程结束（ $t = 0$ ）得到纯净的潜在表征  $x_0$  后，需通过解码器将其还原为具有临床意义的数值，这一步是“模拟比特”回到现实世界的关键。

# （1）特征还原与阈值化

对于拼接张量  $\mathbf{x}_0$  中的不同部分，采用分治解码策略：首先应用高斯逆变换  $x_{num} = F_{emp}^{-1}\bigl (\Phi (\tilde{x}_{num})\bigr)$  。这里  $F_{emp}^{-1}$  是经验累积分布函数的逆函数，通过插值查找表（LookupTable），将  $\mathcal{N}(0,1)$  空间中的数值精确还原为真实的BMI（如24.5）、FEV1（如2.8L）等物理。

其次对于模拟比特向量  $\mathbf{x}_{\text{analog}}$  （此时已是实数值，如[0.9,-0.8])，通过Sigmoid函数将其映射到(0,1）区间，然后应用硬阈值（HardThresholding）操作：

$$
\boldsymbol {b} _ {\text {r e c}} = \mathbb {I} (\operatorname {S i g m o i d} \left(\boldsymbol {x} _ {\text {a n a l o g}}\right) > 0. 5) \tag {38}
$$

其中  $\mathbb{I}(\cdot)$  为指示函数。得到的二进制向量  $\mathbf{b}_{rec}$  （如[1,0]）最后通过查表解码为具体的临床类别（如Stage II）。

# (2) 系统最终输出

经过上述还原，系统输出一个完整的纵向风险轨迹矩阵：

$$
\boldsymbol {X} _ {p r e d} = \left\{\text {Y e a r} _ {1}, \dots , \text {Y e a r} _ {T _ {p r e d}} \right\} \in \mathbb {R} ^ {T _ {p r e d} \times D _ {\text {o r i g i n a l}}} \tag {39}
$$

该矩阵的每一行代表受试者在未来某一年的完整健康画像，包含预测的生理指标数值与患病状态。基于此轨迹，临床医生不仅能看到“是否患癌”，还能看到“BMI是否急剧下降”、“肺功能衰退速度是否异常”等动态演变细节，从而直观判断受试者是否属于“快进展型”高危人群，制定个性化的筛查频率。

